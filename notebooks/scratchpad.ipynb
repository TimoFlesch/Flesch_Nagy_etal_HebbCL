{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad for paper revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import os, sys\n",
    "root_path = os.path.realpath('../')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.data import make_blobs_dataset, make_trees_dataset\n",
    "from utils.nnet import get_device\n",
    "\n",
    "from hebbcl.logger import LoggerFactory\n",
    "from hebbcl.model import Nnet, ScaledNet2Hidden\n",
    "from hebbcl.trainer import Optimiser, train_on_blobs, train_on_trees\n",
    "from hebbcl.parameters import parser\n",
    "from hebbcl.tuner import HPOTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation\n",
    "hpo on network trained with fewer episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: blocked trials with oja_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: Interleaved trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "args.training_schedule = \"interleaved\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_interleaved_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "args.training_schedule = \"interleaved\"\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>done</th>\n",
       "      <th>config.lrate_sgd</th>\n",
       "      <th>config.ctx_scaling</th>\n",
       "      <th>config.seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c1e11c40</th>\n",
       "      <td>-5179.713379</td>\n",
       "      <td>0.84</td>\n",
       "      <td>True</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>4</td>\n",
       "      <td>6112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9eb260f</th>\n",
       "      <td>-435.491669</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>1</td>\n",
       "      <td>9885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9ed0ad4</th>\n",
       "      <td>-225.550491</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>2</td>\n",
       "      <td>8350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9dc93c9</th>\n",
       "      <td>-137.268188</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001514</td>\n",
       "      <td>5</td>\n",
       "      <td>5642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1bf8182</th>\n",
       "      <td>-74.009750</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001368</td>\n",
       "      <td>3</td>\n",
       "      <td>7425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c9ef14d5</th>\n",
       "      <td>-61.272003</td>\n",
       "      <td>0.50</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002444</td>\n",
       "      <td>5</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2840999</th>\n",
       "      <td>-47.112179</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>2</td>\n",
       "      <td>4403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>be5c0ef5</th>\n",
       "      <td>-31.493992</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001812</td>\n",
       "      <td>3</td>\n",
       "      <td>6468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c7d5978e</th>\n",
       "      <td>-27.358358</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>1</td>\n",
       "      <td>7970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cad95164</th>\n",
       "      <td>-26.917624</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>2</td>\n",
       "      <td>2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c1ccc1fc</th>\n",
       "      <td>-19.736513</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>5</td>\n",
       "      <td>1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b2901bd0</th>\n",
       "      <td>-12.985675</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>3</td>\n",
       "      <td>6048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad44a73</th>\n",
       "      <td>-12.679750</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>3</td>\n",
       "      <td>6956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b5ea15e1</th>\n",
       "      <td>-10.386111</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>3</td>\n",
       "      <td>6289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>babbc343</th>\n",
       "      <td>-9.882326</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>3</td>\n",
       "      <td>6268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_loss  mean_acc   done  config.lrate_sgd  config.ctx_scaling  \\\n",
       "trial_id                                                                       \n",
       "c1e11c40 -5179.713379      0.84   True          0.000793                   4   \n",
       "c9eb260f  -435.491669      0.50  False          0.002728                   1   \n",
       "c9ed0ad4  -225.550491      0.50  False          0.002233                   2   \n",
       "c9dc93c9  -137.268188      0.50  False          0.001514                   5   \n",
       "c1bf8182   -74.009750      0.50  False          0.001368                   3   \n",
       "c9ef14d5   -61.272003      0.50   True          0.002444                   5   \n",
       "b2840999   -47.112179      0.50  False          0.000922                   2   \n",
       "be5c0ef5   -31.493992      0.50  False          0.001812                   3   \n",
       "c7d5978e   -27.358358      0.50  False          0.000568                   1   \n",
       "cad95164   -26.917624      0.50  False          0.000963                   2   \n",
       "c1ccc1fc   -19.736513      0.50  False          0.002953                   5   \n",
       "b2901bd0   -12.985675      0.50  False          0.004141                   3   \n",
       "bad44a73   -12.679750      0.50  False          0.000780                   3   \n",
       "b5ea15e1   -10.386111      0.50  False          0.001476                   3   \n",
       "babbc343    -9.882326      0.50  False          0.000755                   3   \n",
       "\n",
       "          config.seed  \n",
       "trial_id               \n",
       "c1e11c40         6112  \n",
       "c9eb260f         9885  \n",
       "c9ed0ad4         8350  \n",
       "c9dc93c9         5642  \n",
       "c1bf8182         7425  \n",
       "c9ef14d5          305  \n",
       "b2840999         4403  \n",
       "be5c0ef5         6468  \n",
       "c7d5978e         7970  \n",
       "cad95164         2612  \n",
       "c1ccc1fc         1771  \n",
       "b2901bd0         6048  \n",
       "bad44a73         6956  \n",
       "b5ea15e1         6289  \n",
       "babbc343         6268  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../results/raytune_trees_interleaved_vanilla_1ctx.pkl\",\"rb\") as f:\n",
    "    df = pickle.load(f)[\"df\"]\n",
    "df.sort_values(\"mean_loss\").head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_loss': -5288.3916015625,\n",
       " 'mean_acc': 0.8424999713897705,\n",
       " 'done': True,\n",
       " 'config.lrate_sgd': 0.001405253754308637,\n",
       " 'config.lrate_hebb': 0.0001261706686407157,\n",
       " 'config.ctx_scaling': 5,\n",
       " 'config.seed': 2789}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_config = dict(df.iloc[2,:])\n",
    "best_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: task a 0.5561, task b 0.0699 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 7 n_b: 1\n",
      "... 2nd hidden: n_a: 6 n_b: 2\n",
      "step 50, loss: task a -0.1111, task b 0.0529 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 6 n_b: 2\n",
      "... 2nd hidden: n_a: 4 n_b: 3\n",
      "step 100, loss: task a -1.2556, task b 0.3045 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 3 n_b: 3\n",
      "... 2nd hidden: n_a: 7 n_b: 2\n",
      "step 150, loss: task a -4.6015, task b 2.7430 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 3 n_b: 2\n",
      "... 2nd hidden: n_a: 4 n_b: 2\n",
      "step 200, loss: task a -8.4972, task b 6.0427 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 3 n_b: 1\n",
      "... 2nd hidden: n_a: 5 n_b: 0\n",
      "step 250, loss: task a -32.5606, task b 21.6849 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 4 n_b: 0\n",
      "... 2nd hidden: n_a: 1 n_b: 1\n",
      "step 300, loss: task a -58.2328, task b 49.9133 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 4 n_b: 0\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 350, loss: task a -138.3925, task b 99.8687 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 2 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 400, loss: task a -214.4110, task b 147.1072 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 2 n_b: 0\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 450, loss: task a -438.1096, task b 223.1302 | acc: task a 0.7450, task b 0.3350\n",
      "...1st hidden: n_a: 2 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 500, loss: task a -988.2891, task b 327.9401 | acc: task a 0.7650, task b 0.3300\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 550, loss: task a -1565.4297, task b 344.1802 | acc: task a 0.8550, task b 0.3400\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 600, loss: task a -2295.7385, task b 506.7356 | acc: task a 0.9200, task b 0.3300\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 650, loss: task a -2788.4500, task b 284.3174 | acc: task a 0.9050, task b 0.4050\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 700, loss: task a -2990.7151, task b 664.6140 | acc: task a 0.9250, task b 0.3800\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 750, loss: task a -3093.9639, task b 432.5575 | acc: task a 0.9200, task b 0.4100\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 800, loss: task a -3204.2578, task b 216.0897 | acc: task a 0.9350, task b 0.4400\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 850, loss: task a -3235.9910, task b 55.0058 | acc: task a 0.9300, task b 0.4650\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 900, loss: task a -3334.4001, task b 374.5701 | acc: task a 0.9550, task b 0.4200\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 950, loss: task a -3321.0881, task b 672.2387 | acc: task a 0.9400, task b 0.3900\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1000, loss: task a -3415.7808, task b 348.0560 | acc: task a 0.9700, task b 0.4300\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1050, loss: task a -3452.4785, task b 188.8990 | acc: task a 0.9700, task b 0.4450\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1100, loss: task a -3474.4316, task b 353.9203 | acc: task a 0.9700, task b 0.4350\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1150, loss: task a -3520.3257, task b 255.5478 | acc: task a 0.9900, task b 0.4400\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1200, loss: task a -3545.4675, task b 230.7391 | acc: task a 0.9900, task b 0.4450\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1250, loss: task a -3492.4524, task b 290.9836 | acc: task a 0.9700, task b 0.4300\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1300, loss: task a -3463.6379, task b -1769.8257 | acc: task a 0.9750, task b 0.7800\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1350, loss: task a -2956.0344, task b -3404.1675 | acc: task a 0.8750, task b 0.9800\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1400, loss: task a -2604.1101, task b -3670.1653 | acc: task a 0.8250, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1450, loss: task a -2565.6418, task b -3689.6428 | acc: task a 0.8150, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1500, loss: task a -2281.5000, task b -3719.6345 | acc: task a 0.7850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1550, loss: task a -2219.1199, task b -3732.2598 | acc: task a 0.7600, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1600, loss: task a -2164.1367, task b -3738.4775 | acc: task a 0.7550, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1650, loss: task a -2020.7438, task b -3735.3735 | acc: task a 0.7250, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1700, loss: task a -2003.0200, task b -3741.5083 | acc: task a 0.7300, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1750, loss: task a -1922.0629, task b -3744.3279 | acc: task a 0.7100, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1800, loss: task a -1903.6274, task b -3745.6396 | acc: task a 0.7100, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1850, loss: task a -1819.8115, task b -3746.3464 | acc: task a 0.7050, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1900, loss: task a -1785.0496, task b -3747.0056 | acc: task a 0.7050, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1950, loss: task a -1721.8503, task b -3747.4553 | acc: task a 0.7000, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2000, loss: task a -1672.0372, task b -3747.6899 | acc: task a 0.7000, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2050, loss: task a -1605.4458, task b -3747.8604 | acc: task a 0.6950, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2100, loss: task a -1587.0422, task b -3746.2896 | acc: task a 0.6900, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2150, loss: task a -1579.8601, task b -3733.0620 | acc: task a 0.6950, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2200, loss: task a -1557.3229, task b -3745.2974 | acc: task a 0.6900, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2250, loss: task a -1473.7921, task b -3746.9922 | acc: task a 0.6800, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2300, loss: task a -1497.2817, task b -3748.0913 | acc: task a 0.6800, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2350, loss: task a -1537.6630, task b -3747.1731 | acc: task a 0.6850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2400, loss: task a -1522.5460, task b -3748.4199 | acc: task a 0.6850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2450, loss: task a -1539.3970, task b -3748.9941 | acc: task a 0.6850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "done\n",
      "config: lrate_sgd: 0.0014, lrate_hebb: 0.0001, context offset: 5\n",
      "terminal accuracy: 0.84, loss: -5288.39\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 100\n",
    "args.n_layers = 2\n",
    "args.n_hidden = 100\n",
    "args.n_features = 974\n",
    "args.ctx_avg = False\n",
    "args.lrate_hebb = best_config[\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = best_config[\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = best_config[\"config.ctx_scaling\"]\n",
    "\n",
    "args.ctx_twice = False\n",
    "args.training_schedule = \"blocked\"\n",
    "args.perform_hebb = True\n",
    "args.centering = True\n",
    "args.gating = \"oja\"\n",
    "\n",
    "np.random.seed(best_config[\"config.seed\"])\n",
    "random.seed(best_config[\"config.seed\"])\n",
    "torch.manual_seed(best_config[\"config.seed\"])\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_trees_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = ScaledNet2Hidden(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_trees(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3ba60a28f1899318f4810ee01fef19e535f7a46e788980dcac9bebef4b464e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
