{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad for paper revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import os, sys\n",
    "root_path = os.path.realpath('../')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.data import make_blobs_dataset, make_trees_dataset\n",
    "from utils.nnet import get_device\n",
    "\n",
    "from hebbcl.logger import LoggerFactory\n",
    "from hebbcl.model import Nnet, ScaledNet2Hidden\n",
    "from hebbcl.trainer import Optimiser, train_on_blobs, train_on_trees\n",
    "from hebbcl.parameters import parser\n",
    "from hebbcl.tuner import HPOTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation\n",
    "hpo on network trained with fewer episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: blocked trials with oja_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: Interleaved trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "args.training_schedule = \"interleaved\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_interleaved_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "args.training_schedule = \"interleaved\"\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: all_oja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>done</th>\n",
       "      <th>config.lrate_sgd</th>\n",
       "      <th>config.ctx_scaling</th>\n",
       "      <th>config.seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a325e_02551</th>\n",
       "      <td>-28.044544</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.076368</td>\n",
       "      <td>7</td>\n",
       "      <td>2894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01146</th>\n",
       "      <td>-28.042593</td>\n",
       "      <td>0.975</td>\n",
       "      <td>True</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>7</td>\n",
       "      <td>3005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01281</th>\n",
       "      <td>-27.508484</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.091234</td>\n",
       "      <td>7</td>\n",
       "      <td>8542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_02688</th>\n",
       "      <td>-27.327234</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.091137</td>\n",
       "      <td>6</td>\n",
       "      <td>490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_00146</th>\n",
       "      <td>-27.020430</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.078242</td>\n",
       "      <td>6</td>\n",
       "      <td>7215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01302</th>\n",
       "      <td>-26.922705</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.098160</td>\n",
       "      <td>6</td>\n",
       "      <td>6678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_00715</th>\n",
       "      <td>-26.824409</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.041682</td>\n",
       "      <td>7</td>\n",
       "      <td>7111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01985</th>\n",
       "      <td>-26.337194</td>\n",
       "      <td>0.900</td>\n",
       "      <td>True</td>\n",
       "      <td>0.050850</td>\n",
       "      <td>7</td>\n",
       "      <td>9028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01519</th>\n",
       "      <td>-26.333696</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.069805</td>\n",
       "      <td>7</td>\n",
       "      <td>7054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_00126</th>\n",
       "      <td>-26.329458</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.063359</td>\n",
       "      <td>6</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01879</th>\n",
       "      <td>-26.304163</td>\n",
       "      <td>0.925</td>\n",
       "      <td>True</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>6</td>\n",
       "      <td>4689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_02567</th>\n",
       "      <td>-26.166382</td>\n",
       "      <td>0.950</td>\n",
       "      <td>True</td>\n",
       "      <td>0.049869</td>\n",
       "      <td>7</td>\n",
       "      <td>5072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01416</th>\n",
       "      <td>-26.158718</td>\n",
       "      <td>0.900</td>\n",
       "      <td>True</td>\n",
       "      <td>0.086926</td>\n",
       "      <td>6</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01406</th>\n",
       "      <td>-26.016325</td>\n",
       "      <td>0.900</td>\n",
       "      <td>True</td>\n",
       "      <td>0.062898</td>\n",
       "      <td>6</td>\n",
       "      <td>8623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a325e_01111</th>\n",
       "      <td>-25.578176</td>\n",
       "      <td>0.900</td>\n",
       "      <td>True</td>\n",
       "      <td>0.097082</td>\n",
       "      <td>7</td>\n",
       "      <td>9776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             mean_loss  mean_acc  done  config.lrate_sgd  config.ctx_scaling  \\\n",
       "trial_id                                                                       \n",
       "a325e_02551 -28.044544     0.950  True          0.076368                   7   \n",
       "a325e_01146 -28.042593     0.975  True          0.084740                   7   \n",
       "a325e_01281 -27.508484     0.950  True          0.091234                   7   \n",
       "a325e_02688 -27.327234     0.950  True          0.091137                   6   \n",
       "a325e_00146 -27.020430     0.950  True          0.078242                   6   \n",
       "a325e_01302 -26.922705     0.950  True          0.098160                   6   \n",
       "a325e_00715 -26.824409     0.950  True          0.041682                   7   \n",
       "a325e_01985 -26.337194     0.900  True          0.050850                   7   \n",
       "a325e_01519 -26.333696     0.950  True          0.069805                   7   \n",
       "a325e_00126 -26.329458     0.950  True          0.063359                   6   \n",
       "a325e_01879 -26.304163     0.925  True          0.092024                   6   \n",
       "a325e_02567 -26.166382     0.950  True          0.049869                   7   \n",
       "a325e_01416 -26.158718     0.900  True          0.086926                   6   \n",
       "a325e_01406 -26.016325     0.900  True          0.062898                   6   \n",
       "a325e_01111 -25.578176     0.900  True          0.097082                   7   \n",
       "\n",
       "             config.seed  \n",
       "trial_id                  \n",
       "a325e_02551         2894  \n",
       "a325e_01146         3005  \n",
       "a325e_01281         8542  \n",
       "a325e_02688          490  \n",
       "a325e_00146         7215  \n",
       "a325e_01302         6678  \n",
       "a325e_00715         7111  \n",
       "a325e_01985         9028  \n",
       "a325e_01519         7054  \n",
       "a325e_00126          393  \n",
       "a325e_01879         4689  \n",
       "a325e_02567         5072  \n",
       "a325e_01416         6600  \n",
       "a325e_01406         8623  \n",
       "a325e_01111         9776  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../results/raytune_blobs_asha_200episodes_blocked_vanilla_1ctx.pkl\",\"rb\") as f:\n",
    "    df = pickle.load(f)[\"df\"]\n",
    "df = df.sort_values(\"mean_loss\").head(15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "step 0, loss: task a -0.4216, task b 0.3495 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 5 n_b: 4\n",
      "... 2nd hidden: n_a: 7 n_b: 7\n",
      "step 50, loss: task a 0.1933, task b -1.9896 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 8 n_b: 6\n",
      "... 2nd hidden: n_a: 1 n_b: 9\n",
      "step 100, loss: task a -1.1461, task b -12.2039 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 6 n_b: 7\n",
      "... 2nd hidden: n_a: 2 n_b: 3\n",
      "step 150, loss: task a -7.9329, task b -36.3379 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 3 n_b: 2\n",
      "... 2nd hidden: n_a: 1 n_b: 2\n",
      "step 200, loss: task a -8.0407, task b -44.7073 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 3 n_b: 2\n",
      "... 2nd hidden: n_a: 1 n_b: 1\n",
      "step 250, loss: task a -34.5834, task b -113.7178 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 1 n_b: 3\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 300, loss: task a -122.8599, task b -120.6186 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 1 n_b: 3\n",
      "... 2nd hidden: n_a: 1 n_b: 2\n",
      "step 350, loss: task a -336.9130, task b -496.4633 | acc: task a 0.5000, task b 0.5000\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 400, loss: task a -900.6320, task b -875.3535 | acc: task a 0.5200, task b 0.6200\n",
      "...1st hidden: n_a: 0 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 450, loss: task a -1016.9380, task b -1765.0420 | acc: task a 0.7200, task b 0.8900\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 1\n",
      "step 500, loss: task a -1617.9528, task b -3349.0581 | acc: task a 0.7400, task b 0.9950\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 550, loss: task a -1884.7600, task b -3474.3730 | acc: task a 0.7500, task b 0.9900\n",
      "...1st hidden: n_a: 1 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 600, loss: task a -2286.0640, task b -3338.4429 | acc: task a 0.7800, task b 0.9400\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 650, loss: task a -2131.5471, task b -3673.5640 | acc: task a 0.7700, task b 0.9950\n",
      "...1st hidden: n_a: 1 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 700, loss: task a -2115.0369, task b -3692.7998 | acc: task a 0.7700, task b 0.9950\n",
      "...1st hidden: n_a: 1 n_b: 1\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 750, loss: task a -2958.2131, task b -3631.4958 | acc: task a 0.8950, task b 0.9850\n",
      "...1st hidden: n_a: 0 n_b: 0\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 800, loss: task a -2987.9241, task b -3687.3506 | acc: task a 0.9000, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 2\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 850, loss: task a -3370.4456, task b -3678.3328 | acc: task a 0.9450, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 1\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 900, loss: task a -3411.5120, task b -3615.6899 | acc: task a 0.9600, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 2\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 950, loss: task a -3413.1382, task b -3657.5193 | acc: task a 0.9350, task b 0.9950\n",
      "...1st hidden: n_a: 1 n_b: 2\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1000, loss: task a -3359.1353, task b -3636.1853 | acc: task a 0.9350, task b 0.9900\n",
      "...1st hidden: n_a: 4 n_b: 3\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1050, loss: task a -2819.8977, task b -3709.2959 | acc: task a 0.8650, task b 0.9950\n",
      "...1st hidden: n_a: 8 n_b: 9\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1100, loss: task a -3366.3850, task b -3727.5381 | acc: task a 0.9350, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 5\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1150, loss: task a -3323.1448, task b -3726.7266 | acc: task a 0.9350, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 5\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1200, loss: task a -3410.3274, task b -3729.7483 | acc: task a 0.9450, task b 0.9950\n",
      "...1st hidden: n_a: 5 n_b: 10\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1250, loss: task a -3549.9014, task b -3713.3120 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 0 n_b: 10\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1300, loss: task a -3611.2942, task b -3725.3262 | acc: task a 0.9800, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1350, loss: task a -3628.1914, task b -3725.1868 | acc: task a 0.9850, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1400, loss: task a -3376.2310, task b -3722.8672 | acc: task a 0.9400, task b 0.9950\n",
      "...1st hidden: n_a: 11 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1450, loss: task a -3633.4451, task b -3726.2173 | acc: task a 0.9900, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1500, loss: task a -3611.6602, task b -3726.8823 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1550, loss: task a -3588.6663, task b -3726.9380 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1600, loss: task a -3574.1272, task b -3726.5833 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 4 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1650, loss: task a -3595.7119, task b -3725.9087 | acc: task a 0.9800, task b 0.9950\n",
      "...1st hidden: n_a: 6 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1700, loss: task a -3210.9348, task b -3722.6106 | acc: task a 0.9150, task b 0.9950\n",
      "...1st hidden: n_a: 12 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1750, loss: task a -3586.4912, task b -3717.6921 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 9 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1800, loss: task a -3568.2585, task b -3726.7922 | acc: task a 0.9700, task b 0.9950\n",
      "...1st hidden: n_a: 8 n_b: 11\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 1850, loss: task a -3595.6082, task b -3743.1677 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 12\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 1900, loss: task a -3616.9043, task b -3742.6858 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 11 n_b: 12\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 1950, loss: task a -3341.2710, task b -3741.2344 | acc: task a 0.9200, task b 1.0000\n",
      "...1st hidden: n_a: 2 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2000, loss: task a -2905.7080, task b -3734.7258 | acc: task a 0.8650, task b 0.9950\n",
      "...1st hidden: n_a: 1 n_b: 12\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2050, loss: task a -3611.8027, task b -3722.0315 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 2 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2100, loss: task a -3599.3682, task b -3727.4087 | acc: task a 0.9750, task b 1.0000\n",
      "...1st hidden: n_a: 2 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2150, loss: task a -3612.4192, task b -3733.0354 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 2 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2200, loss: task a -3533.0396, task b -3730.6729 | acc: task a 0.9700, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 7\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2250, loss: task a -3581.5623, task b -3729.5972 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 3 n_b: 8\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2300, loss: task a -3576.9192, task b -3728.9338 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 5 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2350, loss: task a -3581.5732, task b -3728.1277 | acc: task a 0.9750, task b 0.9950\n",
      "...1st hidden: n_a: 2 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2400, loss: task a -3483.5481, task b -3727.3210 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 1 n_b: 7\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2450, loss: task a -3369.1804, task b -3744.2493 | acc: task a 0.9300, task b 1.0000\n",
      "...1st hidden: n_a: 2 n_b: 16\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2500, loss: task a -3613.0552, task b -3738.9641 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 5 n_b: 15\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2550, loss: task a -3595.5950, task b -3703.8000 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 6 n_b: 18\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2600, loss: task a -3606.3281, task b -3713.4055 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 6 n_b: 18\n",
      "... 2nd hidden: n_a: 0 n_b: 0\n",
      "step 2650, loss: task a -3117.3804, task b -3697.6870 | acc: task a 0.8800, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2700, loss: task a -1748.2727, task b -3689.6091 | acc: task a 0.6900, task b 0.9950\n",
      "...1st hidden: n_a: 10 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2750, loss: task a -3031.6479, task b -3169.4700 | acc: task a 0.8650, task b 0.9400\n",
      "...1st hidden: n_a: 14 n_b: 20\n",
      "... 2nd hidden: n_a: 3 n_b: 0\n",
      "step 2800, loss: task a -3071.0867, task b -3744.4407 | acc: task a 0.8700, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 2 n_b: 0\n",
      "step 2850, loss: task a -3249.7227, task b -3745.1245 | acc: task a 0.9200, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 2 n_b: 0\n",
      "step 2900, loss: task a -3288.2659, task b -3744.1299 | acc: task a 0.9250, task b 1.0000\n",
      "...1st hidden: n_a: 13 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 2950, loss: task a -3403.1587, task b -3741.9680 | acc: task a 0.9400, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3000, loss: task a -3547.7190, task b -3740.0483 | acc: task a 0.9600, task b 1.0000\n",
      "...1st hidden: n_a: 4 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3050, loss: task a -3471.2285, task b -3734.7139 | acc: task a 0.9450, task b 0.9950\n",
      "...1st hidden: n_a: 6 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3100, loss: task a -3559.1733, task b -3732.9312 | acc: task a 0.9600, task b 0.9950\n",
      "...1st hidden: n_a: 6 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3150, loss: task a -3528.0522, task b -3731.4885 | acc: task a 0.9650, task b 0.9950\n",
      "...1st hidden: n_a: 8 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3200, loss: task a -3511.8560, task b -3729.8777 | acc: task a 0.9600, task b 0.9950\n",
      "...1st hidden: n_a: 9 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3250, loss: task a -3493.8008, task b -3728.6938 | acc: task a 0.9600, task b 0.9950\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3300, loss: task a -3476.9324, task b -3727.7732 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3350, loss: task a -3462.5146, task b -3727.0203 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3400, loss: task a -3451.0781, task b -3726.4409 | acc: task a 0.9500, task b 0.9950\n",
      "...1st hidden: n_a: 12 n_b: 18\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3450, loss: task a -3442.7734, task b -3725.9878 | acc: task a 0.9500, task b 0.9950\n",
      "...1st hidden: n_a: 13 n_b: 17\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3500, loss: task a -3443.5449, task b -3725.5166 | acc: task a 0.9500, task b 0.9950\n",
      "...1st hidden: n_a: 14 n_b: 16\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3550, loss: task a -3491.4551, task b -3725.0933 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 13 n_b: 16\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3600, loss: task a -3516.3850, task b -3724.3330 | acc: task a 0.9650, task b 0.9950\n",
      "...1st hidden: n_a: 14 n_b: 16\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3650, loss: task a -3486.4023, task b -3722.9800 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 14 n_b: 16\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3700, loss: task a -3475.4822, task b -3722.3516 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 14 n_b: 16\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3750, loss: task a -3479.4312, task b -3725.3313 | acc: task a 0.9550, task b 0.9950\n",
      "...1st hidden: n_a: 14 n_b: 17\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3800, loss: task a -3351.4292, task b -3749.9526 | acc: task a 0.9400, task b 1.0000\n",
      "...1st hidden: n_a: 14 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3850, loss: task a -3359.9326, task b -3749.9460 | acc: task a 0.9400, task b 1.0000\n",
      "...1st hidden: n_a: 14 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3900, loss: task a -3570.1714, task b -3749.9026 | acc: task a 0.9700, task b 1.0000\n",
      "...1st hidden: n_a: 11 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 3950, loss: task a -3557.3467, task b -3749.8674 | acc: task a 0.9650, task b 1.0000\n",
      "...1st hidden: n_a: 11 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4000, loss: task a -3642.2776, task b -3749.7241 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4050, loss: task a -3620.9666, task b -3749.5823 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4100, loss: task a -3641.5422, task b -3749.4258 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 3 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4150, loss: task a -3655.0579, task b -3748.5530 | acc: task a 0.9900, task b 1.0000\n",
      "...1st hidden: n_a: 10 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4200, loss: task a -3673.7993, task b -3747.8931 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 10 n_b: 13\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4250, loss: task a -3645.4026, task b -3746.6404 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 13\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4300, loss: task a -3511.1829, task b -3744.9890 | acc: task a 0.9650, task b 1.0000\n",
      "...1st hidden: n_a: 12 n_b: 12\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4350, loss: task a -3680.7104, task b -3742.7141 | acc: task a 0.9900, task b 1.0000\n",
      "...1st hidden: n_a: 8 n_b: 12\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4400, loss: task a -3675.2351, task b -3740.8025 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 7 n_b: 12\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4450, loss: task a -3565.9561, task b -3736.6541 | acc: task a 0.9700, task b 0.9950\n",
      "...1st hidden: n_a: 0 n_b: 11\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4500, loss: task a -3623.1021, task b -3747.6294 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4550, loss: task a -3631.0823, task b -3748.6487 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4600, loss: task a -3628.9795, task b -3749.7534 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4650, loss: task a -3629.9258, task b -3749.7964 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4700, loss: task a -3624.3657, task b -3749.8616 | acc: task a 0.9850, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4750, loss: task a -3619.0486, task b -3749.8958 | acc: task a 0.9800, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4800, loss: task a -3723.2742, task b -3749.9294 | acc: task a 1.0000, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4850, loss: task a -3721.3059, task b -3749.9492 | acc: task a 1.0000, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4900, loss: task a -3696.3552, task b -3749.9573 | acc: task a 0.9900, task b 1.0000\n",
      "...1st hidden: n_a: 0 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "step 4950, loss: task a -3698.1287, task b -3749.9690 | acc: task a 0.9900, task b 1.0000\n",
      "...1st hidden: n_a: 1 n_b: 14\n",
      "... 2nd hidden: n_a: 1 n_b: 0\n",
      "done\n",
      "config: lrate_sgd: 0.0035, lrate_hebb: 0.0001, context offset: 3\n",
      "terminal accuracy: 1.00, loss: -7448.10\n"
     ]
    }
   ],
   "source": [
    "# verify results \n",
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 200\n",
    "args.n_layers = 2\n",
    "args.n_features = 974\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "args.training_schedule = \"interleaved\"\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_trees_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = ScaledNet2Hidden(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_trees(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    8.6s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:   13.1s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:   15.7s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   18.5s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   22.3s\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:   24.6s remaining:    2.6s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:   26.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    6.3s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    8.7s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   15.2s\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:   17.8s remaining:    1.9s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:   19.7s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   12.2s\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:   14.0s remaining:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:   15.1s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:    1.5s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:   12.8s\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:   15.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:   16.6s finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   44.7s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   45.2s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:  6.6min remaining:   43.7s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   48.9s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   49.6s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:  6.6min remaining:   43.9s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  7.1min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   51.1s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:  6.5min remaining:   43.6s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  7.0min finished\n",
      "[Parallel(n_jobs=6)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=6)]: Done   1 tasks      | elapsed:   51.5s\n",
      "[Parallel(n_jobs=6)]: Done   6 tasks      | elapsed:   52.2s\n",
      "[Parallel(n_jobs=6)]: Done  13 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=6)]: Done  20 tasks      | elapsed:  3.6min\n",
      "[Parallel(n_jobs=6)]: Done  29 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=6)]: Done  38 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=6)]: Done  45 out of  50 | elapsed:  6.6min remaining:   44.1s\n",
      "[Parallel(n_jobs=6)]: Done  50 out of  50 | elapsed:  7.1min finished\n"
     ]
    }
   ],
   "source": [
    "from hebbcl.tuner import validate_tuner_results\n",
    "\n",
    "n_episodes = [8, 200]\n",
    "configs = [    \n",
    "    \"blocked_ojaall_1ctx\",    \n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    for ep in n_episodes:\n",
    "        for i in range(1,5):\n",
    "            validate_tuner_results(filename=\"blobs_asha_\"+str(ep)+\"episodes_\" + cfg,filepath=\"../results/\",datapath=\"../datasets/\", whichtrial=i,njobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# %matplotlib qt\n",
    "n_runs = 50\n",
    "n_episodes = 8\n",
    "models = ['blobs_asha_8episodes_interleaved_ojaall_1ctx','blobs_asha_8episodes_blocked_ojaall_1ctx_1']\n",
    "\n",
    "# acc\n",
    "f1, axs1 = plt.subplots(2,1,figsize=(2.7,3),dpi=300)\n",
    "# # unit alloc\n",
    "f2, axs2 = plt.subplots(2,1,figsize=(2.7,3),dpi=300)\n",
    "# # context corr \n",
    "f3, axs3 = plt.subplots(2,1,figsize=(2.7,3),dpi=300)\n",
    "# # choice matrices \n",
    "f4, axs4 = plt.subplots(2,2,figsize=(5,5),dpi=300)\n",
    "# # hidden layer MDS, interleaved\n",
    "# f5a, axs5a = plt.subplots(1,2,figsize=(10,3),dpi=300)\n",
    "# # hidden layer MDS, blocked\n",
    "# f5a, axs5a = plt.subplots(1,2,figsize=(10,3),dpi=300)\n",
    "\n",
    "\n",
    "for i,m in enumerate(models):\n",
    "    t_a = np.empty((n_runs,n_episodes))\n",
    "    t_b = np.empty((n_runs,n_episodes))\n",
    "    t_d = np.empty((n_runs,n_episodes))\n",
    "    t_mixed = np.empty((n_runs,n_episodes))\n",
    "    acc_1st = np.empty((n_runs,n_episodes))\n",
    "    acc_2nd = np.empty((n_runs,n_episodes))\n",
    "    contextcorr = np.empty((n_runs,n_episodes))\n",
    "    cmats_a = []\n",
    "    cmats_b = []\n",
    "\n",
    "    for r in range(n_runs):\n",
    "        with open('../checkpoints/'+m+'/run_'+str(r)+'/results.pkl', 'rb') as f:\n",
    "            results = pickle.load(f)\n",
    "            \n",
    "            # accuracy:\n",
    "            acc_1st[r,:] = results['acc_1st']\n",
    "            acc_2nd[r,:] = results['acc_2nd']\n",
    "            # task factorisation:\n",
    "            t_a[r,:] = results['n_only_b_regr']/100\n",
    "            t_b[r,:] = results['n_only_a_regr']/100\n",
    "            t_d[r,:] = results['n_dead']/100\n",
    "            t_mixed[r,:] = 1-t_a[r,:]-t_b[r,:]-t_d[r,:]\n",
    "            # context correlation:\n",
    "            contextcorr[r,:] = results['w_context_corr']\n",
    "            cc = np.clip(results['all_y_out'][1,:], -709.78, 709.78).astype(np.float64)\n",
    "            choices = 1/(1+np.exp(-cc))\n",
    "            cmats_a.append(choices[:25].reshape(5,5))\n",
    "            cmats_b.append(choices[25:].reshape(5,5))\n",
    "            \n",
    "    cmats_a = np.array(cmats_a)\n",
    "    cmats_b = np.array(cmats_b)\n",
    "    \n",
    "    # accuracy\n",
    "    axs1[i].plot(np.arange(n_episodes),acc_1st.mean(0),color='orange')\n",
    "    axs1[i].fill_between(np.arange(n_episodes),acc_1st.mean(0)-np.std(acc_1st,0)/np.sqrt(n_runs),acc_1st.mean(0)+np.std(acc_1st,0)/np.sqrt(n_runs),alpha=0.5,color='orange',edgecolor=None)\n",
    "    axs1[i].plot(np.arange(n_episodes),acc_2nd.mean(0),color='blue')\n",
    "    axs1[i].fill_between(np.arange(n_episodes),acc_2nd.mean(0)-np.std(acc_2nd,0)/np.sqrt(n_runs),acc_2nd.mean(0)+np.std(acc_2nd,0)/np.sqrt(n_runs),alpha=0.5,color='blue',edgecolor=None)\n",
    "    axs1[i].set_ylim([0.4,1.05])\n",
    "    axs1[i].set(xlabel='trial', ylabel='accuracy')\n",
    "    axs1[i].legend(['1st task','2nd task'],frameon=False)\n",
    "    if 'interleaved' not in m:\n",
    "        axs1[i].plot([n_episodes/2, n_episodes/2],[0,1],'k--',alpha=0.5)\n",
    "    axs1[i].set_title(m.split('_')[1])\n",
    "    plt.gcf()\n",
    "    sns.despine(f1)\n",
    "    f1.tight_layout()\n",
    "\n",
    "    # unit allocation (task factorisation)\n",
    "    axs2[i].plot(np.arange(n_episodes),t_b.mean(0),color='orange')\n",
    "    axs2[i].fill_between(np.arange(n_episodes),t_b.mean(0)-np.std(t_b,0)/np.sqrt(n_runs),t_b.mean(0)+np.std(t_b,0)/np.sqrt(n_runs),alpha=0.5,color='orange',edgecolor=None)\n",
    "    axs2[i].plot(np.arange(n_episodes),t_a.mean(0),color='blue')\n",
    "    axs2[i].fill_between(np.arange(n_episodes),t_a.mean(0)-np.std(t_a,0)/np.sqrt(n_runs),t_a.mean(0)+np.std(t_a,0)/np.sqrt(n_runs),alpha=0.5,color='blue',edgecolor=None)    \n",
    "    axs2[i].set_yticks([0,0.5,1])\n",
    "    ticks = axs2[i].get_yticks()#plt.yticks()\n",
    "    axs2[i].set_yticklabels((int(x) for x in ticks*100))\n",
    "    axs2[i].set(xlabel='trial',ylabel='task-sel (%)')\n",
    "    axs2[i].legend(['1st task','2nd task'],frameon=False)\n",
    "    if 'interleaved' not in m:\n",
    "        axs2[i].plot([n_episodes/2, n_episodes/2],[0,1],'k--',alpha=0.5)\n",
    "    axs2[i].set_title(m.split('_')[1])\n",
    "    plt.gcf()\n",
    "    sns.despine(f2)\n",
    "    axs2[i].set_ylim([0,1.05])    \n",
    "    f2.tight_layout()\n",
    "\n",
    "    # context corr \n",
    "    axs3[i].plot(np.arange(n_episodes),contextcorr.mean(0),color='k')    \n",
    "    axs3[i].fill_between(np.arange(n_episodes),contextcorr.mean(0)-np.std(contextcorr,0)/np.sqrt(n_runs),contextcorr.mean(0)+np.std(contextcorr,0)/np.sqrt(n_runs),alpha=0.5,color='magenta',edgecolor=None)\n",
    "    \n",
    "    axs3[i].set_ylim([-1.1,1.05])\n",
    "    axs3[i].set(xlabel='trial',ylabel=r'$w_{context}$ corr ')    \n",
    "    if 'interleaved' not in m:\n",
    "        axs3[i].plot([n_episodes/2, n_episodes/2],[-1,1],'k--',alpha=0.5)\n",
    "    axs3[i].set_title(m.split('_')[1])\n",
    "    sns.despine(f3)\n",
    "    f3.tight_layout()\n",
    "\n",
    "\n",
    "    # choice matrices \n",
    "    \n",
    "    axs4[i,0].imshow(cmats_a.mean(0))\n",
    "    axs4[i,0].set_title('1st task')\n",
    "    axs4[i,0].set(xticks=[0,2,4],yticks=[0,2,4],xlabel='irrel',ylabel='rel')\n",
    "    axs4[i,1].imshow(cmats_b.mean(0))\n",
    "    axs4[i,1].set(xticks=[0,2,4],yticks=[0,2,4],xlabel='rel',ylabel='irrel')\n",
    "    axs4[i,1].set_title('2nd task')\n",
    "    # PCM=axs4[i,1].get_children()[-2] #get the mappable, the 1st and the 2nd are the x and y axes\n",
    "    \n",
    "    # plt.subplots_adjust(bottom=0.1, right=0.8, top=0.9)\n",
    "    # cax = plt.axes([0.85, 0.1, 0.075, 0.8])\n",
    "    # plt.colorbar(PCM,cax=cax)      \n",
    "\n",
    "\n",
    "    # hidden layer MDS \n",
    "\n",
    "f1.tight_layout()\n",
    "f2.tight_layout()\n",
    "f3.tight_layout()\n",
    "f4.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_2nd[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3ba60a28f1899318f4810ee01fef19e535f7a46e788980dcac9bebef4b464e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
