{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad for paper revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import os, sys\n",
    "root_path = os.path.realpath('../')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.data import make_blobs_dataset\n",
    "from utils.nnet import get_device\n",
    "\n",
    "from hebbcl.logger import LoggerFactory\n",
    "from hebbcl.model import Nnet\n",
    "from hebbcl.trainer import Optimiser, train_on_blobs\n",
    "from hebbcl.parameters import parser\n",
    "from hebbcl.tuner import HPOTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation\n",
    "hpo on network trained with fewer episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: blocked trials with oja_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: Interleaved trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "args.training_schedule = \"interleaved\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_interleaved_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "args.training_schedule = \"interleaved\"\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HPO: Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>done</th>\n",
       "      <th>config.lrate_sgd</th>\n",
       "      <th>config.ctx_scaling</th>\n",
       "      <th>config.seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7f5fd4aa</th>\n",
       "      <td>-7205.236816</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002953</td>\n",
       "      <td>5</td>\n",
       "      <td>1771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637badfa</th>\n",
       "      <td>-5630.119141</td>\n",
       "      <td>0.8700</td>\n",
       "      <td>True</td>\n",
       "      <td>0.011449</td>\n",
       "      <td>2</td>\n",
       "      <td>3593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8e09fac0</th>\n",
       "      <td>-3750.000000</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>7</td>\n",
       "      <td>990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172edb2</th>\n",
       "      <td>-3744.860840</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.021399</td>\n",
       "      <td>3</td>\n",
       "      <td>7119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80c2fd2b</th>\n",
       "      <td>-3733.908447</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>7</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895c18cc</th>\n",
       "      <td>-3749.991211</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.014770</td>\n",
       "      <td>6</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89761245</th>\n",
       "      <td>-3749.929688</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>False</td>\n",
       "      <td>0.013007</td>\n",
       "      <td>4</td>\n",
       "      <td>7204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89456fe7</th>\n",
       "      <td>-2628.006104</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>False</td>\n",
       "      <td>0.018536</td>\n",
       "      <td>4</td>\n",
       "      <td>9429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722a7ba8</th>\n",
       "      <td>-1800.143677</td>\n",
       "      <td>0.6125</td>\n",
       "      <td>False</td>\n",
       "      <td>0.035315</td>\n",
       "      <td>1</td>\n",
       "      <td>1681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4b83d7f5</th>\n",
       "      <td>-1673.614990</td>\n",
       "      <td>0.5925</td>\n",
       "      <td>False</td>\n",
       "      <td>0.082276</td>\n",
       "      <td>3</td>\n",
       "      <td>2032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561edf4a</th>\n",
       "      <td>-250.000000</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>False</td>\n",
       "      <td>0.053865</td>\n",
       "      <td>2</td>\n",
       "      <td>8261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c2fe290a</th>\n",
       "      <td>0.181940</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.003160</td>\n",
       "      <td>2</td>\n",
       "      <td>4780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c30dbf06</th>\n",
       "      <td>-0.280366</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.007932</td>\n",
       "      <td>1</td>\n",
       "      <td>6236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c317a266</th>\n",
       "      <td>0.697312</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>2</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c01cb0ce</th>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>False</td>\n",
       "      <td>0.002195</td>\n",
       "      <td>1</td>\n",
       "      <td>8999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean_loss  mean_acc   done  config.lrate_sgd  config.ctx_scaling  \\\n",
       "trial_id                                                                       \n",
       "7f5fd4aa -7205.236816    0.9700   True          0.002953                   5   \n",
       "637badfa -5630.119141    0.8700   True          0.011449                   2   \n",
       "8e09fac0 -3750.000000    0.7500  False          0.013574                   7   \n",
       "9172edb2 -3744.860840    0.7500  False          0.021399                   3   \n",
       "80c2fd2b -3733.908447    0.7500  False          0.006936                   7   \n",
       "895c18cc -3749.991211    0.7500  False          0.014770                   6   \n",
       "89761245 -3749.929688    0.7500  False          0.013007                   4   \n",
       "89456fe7 -2628.006104    0.6400  False          0.018536                   4   \n",
       "722a7ba8 -1800.143677    0.6125  False          0.035315                   1   \n",
       "4b83d7f5 -1673.614990    0.5925  False          0.082276                   3   \n",
       "561edf4a  -250.000000    0.5250  False          0.053865                   2   \n",
       "c2fe290a     0.181940    0.5000  False          0.003160                   2   \n",
       "c30dbf06    -0.280366    0.5000  False          0.007932                   1   \n",
       "c317a266     0.697312    0.5000  False          0.000338                   2   \n",
       "c01cb0ce     0.034817    0.5000  False          0.002195                   1   \n",
       "\n",
       "          config.seed  \n",
       "trial_id               \n",
       "7f5fd4aa         1771  \n",
       "637badfa         3593  \n",
       "8e09fac0          990  \n",
       "9172edb2         7119  \n",
       "80c2fd2b         1706  \n",
       "895c18cc          753  \n",
       "89761245         7204  \n",
       "89456fe7         9429  \n",
       "722a7ba8         1681  \n",
       "4b83d7f5         2032  \n",
       "561edf4a         8261  \n",
       "c2fe290a         4780  \n",
       "c30dbf06         6236  \n",
       "c317a266          538  \n",
       "c01cb0ce         8999  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../results/raytune_trees_interleaved_vanilla_1ctx.pkl\",\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "df = data[\"df\"]\n",
    "df.sort_values(\"mean_acc\",ascending=False).head(15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3ba60a28f1899318f4810ee01fef19e535f7a46e788980dcac9bebef4b464e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
