{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad for paper revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pickle\n",
    "import os, sys\n",
    "root_path = os.path.realpath('../')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "from utils.data import make_blobs_dataset, make_trees_dataset\n",
    "from utils.nnet import get_device\n",
    "\n",
    "from hebbcl.logger import LoggerFactory\n",
    "from hebbcl.model import Nnet, ScaledNet2Hidden\n",
    "from hebbcl.trainer import Optimiser, train_on_blobs, train_on_trees\n",
    "from hebbcl.parameters import parser\n",
    "from hebbcl.tuner import HPOTuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation\n",
    "hpo on network trained with fewer episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: blocked trials with oja_ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "\n",
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "with open(\"../results/raytune_oja_ctx_blocked_8episodes.pkl\", \"rb\") as f:\n",
    "    df = pickle.load(f)\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: Interleaved trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HPO on blocked trials with oja_ctx\n",
    "args = parser.parse_args(args=[])\n",
    "args.n_episodes = 8\n",
    "args.hpo_fixedseed = True\n",
    "args.hpo_scheduler = \"bohb\"\n",
    "args.hpo_searcher = \"bohb\"\n",
    "args.training_schedule = \"interleaved\"\n",
    "# dict(sorted(vars(args).items(),key=lambda k: k[0]))\n",
    "args.ctx_avg = False\n",
    "# init tuner\n",
    "tuner = HPOTuner(args, time_budget=60*15, metric=\"loss\")\n",
    "\n",
    "tuner.tune(n_samples=500)\n",
    "\n",
    "df = tuner.results\n",
    "df = df[[\"mean_loss\", \"mean_acc\", \"config.lrate_sgd\",\"config.lrate_hebb\", \"config.ctx_scaling\",\"config.seed\",\"done\"]]\n",
    "df = df[df[\"done\"]==True]\n",
    "df = df.drop(columns=[\"done\"])\n",
    "df = df.dropna()\n",
    "df = df.sort_values(\"mean_loss\",ascending=True)\n",
    "\n",
    "df.reset_index()\n",
    "print(df.head(15))\n",
    "\n",
    "print(tuner.best_cfg)\n",
    "\n",
    "with open(\"../results/raytune_oja_ctx_interleaved_8episodes.pkl\", \"wb\") as f:\n",
    "    pickle.dump(df, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify results \n",
    "\n",
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "\n",
    "# override defaults \n",
    "args.n_episodes = 8\n",
    "args.lrate_hebb = df.iloc[0][\"config.lrate_hebb\"]\n",
    "args.lrate_sgd = df.iloc[0][\"config.lrate_sgd\"]\n",
    "args.ctx_scaling = df.iloc[0][\"config.ctx_scaling\"]\n",
    "args.ctx_avg = False\n",
    "args.training_schedule = \"interleaved\"\n",
    "np.random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "random.seed(int(df.iloc[0][\"config.seed\"]))\n",
    "torch.manual_seed(int(df.iloc[0][\"config.seed\"]))\n",
    "\n",
    "\n",
    "\n",
    "# create dataset \n",
    "dataset = make_blobs_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = LoggerFactory.create(args, save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)\n",
    "\n",
    "\n",
    "# train model\n",
    "train_on_blobs(args, model, optimiser, dataset, logger)\n",
    "\n",
    "print(f\"config: lrate_sgd: {args.lrate_sgd:.4f}, lrate_hebb: {args.lrate_hebb:.4f}, context offset: {args.ctx_scaling}\")\n",
    "print(f\"terminal accuracy: {logger.results['acc_total'][-1]:.2f}, loss: {logger.results['losses_total'][-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO: all_oja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../results/raytune_blobs_asha_200episodes_blocked_vanilla_1ctx.pkl\",\"rb\") as f:\n",
    "    df = pickle.load(f)[\"df\"]\n",
    "df = df.sort_values(\"mean_loss\").head(15)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hebbcl.tuner import validate_tuner_results\n",
    "\n",
    "n_episodes = [8, 200]\n",
    "configs = [    \n",
    "    \"blocked_ojaall_1ctx\",    \n",
    "]\n",
    "\n",
    "for cfg in configs:\n",
    "    for ep in n_episodes:\n",
    "        for i in range(1,5):\n",
    "            validate_tuner_results(filename=\"blobs_asha_\"+str(ep)+\"episodes_\" + cfg,filepath=\"../results/\",datapath=\"../datasets/\", whichtrial=i,njobs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_loss</th>\n",
       "      <th>mean_acc</th>\n",
       "      <th>done</th>\n",
       "      <th>config.lrate_sgd</th>\n",
       "      <th>config.lrate_hebb</th>\n",
       "      <th>config.seed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>config.ctx_scaling</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-6434.500000</td>\n",
       "      <td>0.912500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001682</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5545.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5174.355713</td>\n",
       "      <td>0.842500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001929</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>6966.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-4708.075114</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001295</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>6959.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-4651.364502</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>5681.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-4594.206578</td>\n",
       "      <td>0.797321</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000072</td>\n",
       "      <td>4417.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-4393.028039</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>5976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4362.949127</td>\n",
       "      <td>0.785469</td>\n",
       "      <td>True</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>4209.687500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-4287.480078</td>\n",
       "      <td>0.779500</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>5909.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4185.430130</td>\n",
       "      <td>0.774375</td>\n",
       "      <td>True</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>4849.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4040.455191</td>\n",
       "      <td>0.767692</td>\n",
       "      <td>True</td>\n",
       "      <td>0.007736</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>5907.230769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4124.181213</td>\n",
       "      <td>0.754375</td>\n",
       "      <td>True</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>5901.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-3770.149231</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>4060.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3746.350830</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>3699.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3746.753906</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>True</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>7653.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      mean_loss  mean_acc  done  config.lrate_sgd  \\\n",
       "config.ctx_scaling                                                  \n",
       "15                 -6434.500000  0.912500  True          0.001682   \n",
       "13                 -5174.355713  0.842500  True          0.001929   \n",
       "11                 -4708.075114  0.806667  True          0.001295   \n",
       "7                  -4651.364502  0.802083  True          0.005284   \n",
       "6                  -4594.206578  0.797321  True          0.002876   \n",
       "5                  -4393.028039  0.788462  True          0.005493   \n",
       "4                  -4362.949127  0.785469  True          0.004736   \n",
       "8                  -4287.480078  0.779500  True          0.001843   \n",
       "3                  -4185.430130  0.774375  True          0.005208   \n",
       "2                  -4040.455191  0.767692  True          0.007736   \n",
       "9                  -4124.181213  0.754375  True          0.002581   \n",
       "10                 -3770.149231  0.750000  True          0.001143   \n",
       "12                 -3746.350830  0.750000  True          0.001094   \n",
       "16                 -3746.753906  0.750000  True          0.001546   \n",
       "\n",
       "                    config.lrate_hebb  config.seed  \n",
       "config.ctx_scaling                                  \n",
       "15                           0.000010  5545.000000  \n",
       "13                           0.000017  6966.000000  \n",
       "11                           0.000019  6959.666667  \n",
       "7                            0.000038  5681.333333  \n",
       "6                            0.000072  4417.500000  \n",
       "5                            0.000063  5976.000000  \n",
       "4                            0.000081  4209.687500  \n",
       "8                            0.000033  5909.600000  \n",
       "3                            0.000153  4849.437500  \n",
       "2                            0.000081  5907.230769  \n",
       "9                            0.000030  5901.000000  \n",
       "10                           0.000030  4060.000000  \n",
       "12                           0.000022  3699.000000  \n",
       "16                           0.000014  7653.000000  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../results/raytune_trees_asha_blocked_ojaall_1ctx.pkl\",\"rb\") as f:\n",
    "    df = pickle.load(f)[\"df\"]\n",
    "df = df.sort_values(\"mean_loss\").head(100)\n",
    "df.groupby(\"config.ctx_scaling\").mean().sort_values(\"mean_acc\",ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3ba60a28f1899318f4810ee01fef19e535f7a46e788980dcac9bebef4b464e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
