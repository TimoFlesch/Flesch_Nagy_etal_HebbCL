{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratchpad for paper revisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "root_path = os.path.realpath('../')\n",
    "sys.path.append(root_path)\n",
    "\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.data import make_dataset\n",
    "from utils.nnet import get_device\n",
    "\n",
    "from hebbcl.logger import MetricLogger\n",
    "from hebbcl.model import Nnet\n",
    "from hebbcl.trainer import Optimiser, train_model\n",
    "from hebbcl.parameters import parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain params\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# set checkpoint directory\n",
    "save_dir = (\n",
    "        Path(\"checkpoints\") / \"test_allhebb\"\n",
    "    ) \n",
    "\n",
    "# get device (gpu/cpu)\n",
    "args.device = get_device(args.cuda)[0]\n",
    "# vars(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# override defaults \n",
    "args.gating = \"oja\"\n",
    "args.perform_hebb = True\n",
    "args.centering = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# create dataset \n",
    "dataset = make_dataset(args)\n",
    "\n",
    "# instantiate logger, model and optimiser:\n",
    "logger = MetricLogger(save_dir)\n",
    "model = Nnet(args)\n",
    "optimiser = Optimiser(args)\n",
    "\n",
    "# send model to device (GPU?)\n",
    "model = model.to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss: task a 0.0314, task b 0.0384 | acc: task a 0.5000, task b 0.5000\n",
      "... n_a: 4 n_b: 3\n",
      "step 50, loss: task a -0.8582, task b 0.0862 | acc: task a 0.5000, task b 0.4500\n",
      "... n_a: 4 n_b: 3\n",
      "step 100, loss: task a -1.6642, task b 0.0469 | acc: task a 0.9000, task b 0.5000\n",
      "... n_a: 9 n_b: 4\n",
      "step 150, loss: task a -2.3492, task b 0.0497 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 10 n_b: 3\n",
      "step 200, loss: task a -3.0174, task b 0.0459 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 14 n_b: 6\n",
      "step 250, loss: task a -3.7289, task b 0.0451 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 6\n",
      "step 300, loss: task a -4.6146, task b 0.0220 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 7\n",
      "step 350, loss: task a -5.5995, task b 0.0538 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 8\n",
      "step 400, loss: task a -6.6427, task b 0.0585 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 8\n",
      "step 450, loss: task a -7.7101, task b 0.0457 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 500, loss: task a -8.9571, task b 0.0540 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 10\n",
      "step 550, loss: task a -9.7875, task b 0.0327 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 600, loss: task a -10.8245, task b 0.0230 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 650, loss: task a -11.3309, task b 0.0195 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 700, loss: task a -11.7562, task b 0.0246 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 750, loss: task a -12.3974, task b 0.0173 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 17 n_b: 9\n",
      "step 800, loss: task a -12.8112, task b 0.0069 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 17 n_b: 9\n",
      "step 850, loss: task a -13.1266, task b 0.0108 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 900, loss: task a -13.3465, task b 0.0135 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 950, loss: task a -13.4635, task b 0.0173 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1000, loss: task a -13.6365, task b -0.0000 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1050, loss: task a -13.8209, task b 0.0143 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1100, loss: task a -13.9175, task b 0.0167 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1150, loss: task a -14.0160, task b -0.0013 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1200, loss: task a -14.0786, task b 0.0007 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1250, loss: task a -14.1580, task b -0.0034 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1300, loss: task a -14.2169, task b -0.0023 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1350, loss: task a -14.2691, task b -0.0038 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1400, loss: task a -14.3183, task b -0.0044 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1450, loss: task a -14.3625, task b -0.0045 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 18 n_b: 9\n",
      "step 1500, loss: task a -14.4025, task b -0.0063 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1550, loss: task a -14.4360, task b -0.0080 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1600, loss: task a -14.4689, task b -0.0012 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1650, loss: task a -14.4930, task b -0.0078 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1700, loss: task a -14.5136, task b -0.0078 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1750, loss: task a -14.5385, task b -0.0081 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1800, loss: task a -14.5617, task b -0.0088 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1850, loss: task a -14.5781, task b -0.0082 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1900, loss: task a -14.5955, task b -0.0070 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 1950, loss: task a -14.6140, task b -0.0092 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 2000, loss: task a -14.6285, task b -0.0094 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 19 n_b: 9\n",
      "step 2050, loss: task a -14.6447, task b -0.0104 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 2100, loss: task a -14.6580, task b -0.0101 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 2150, loss: task a -14.6674, task b -0.0059 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 20 n_b: 9\n",
      "step 2200, loss: task a -14.6841, task b -0.0063 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2250, loss: task a -14.6919, task b -0.0128 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2300, loss: task a -14.7030, task b -0.0106 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2350, loss: task a -14.7126, task b -0.0120 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2400, loss: task a -14.7220, task b -0.0128 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2450, loss: task a -14.7299, task b -0.0142 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2500, loss: task a -14.7372, task b -0.0174 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2550, loss: task a -14.7460, task b -0.0134 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2600, loss: task a -14.7531, task b -0.0138 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2650, loss: task a -14.7606, task b -0.0141 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2700, loss: task a -14.7684, task b -0.0180 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2750, loss: task a -14.7733, task b -0.0144 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2800, loss: task a -14.7790, task b -0.0147 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2850, loss: task a -14.7855, task b -0.0159 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2900, loss: task a -14.7899, task b -0.0149 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 2950, loss: task a -14.7947, task b -0.0185 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3000, loss: task a -14.8009, task b -0.0158 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3050, loss: task a -14.8052, task b -0.0153 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3100, loss: task a -14.8096, task b -0.0155 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3150, loss: task a -14.8139, task b -0.0156 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3200, loss: task a -14.8181, task b -0.0155 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3250, loss: task a -14.8219, task b -0.0158 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3300, loss: task a -14.8249, task b -0.0129 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3350, loss: task a -14.8298, task b -0.0160 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3400, loss: task a -14.8332, task b -0.0152 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3450, loss: task a -14.8362, task b -0.0161 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3500, loss: task a -14.8396, task b -0.0161 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 21 n_b: 9\n",
      "step 3550, loss: task a -14.8427, task b -0.0161 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3600, loss: task a -14.8454, task b -0.0168 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3650, loss: task a -14.8484, task b -0.0166 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3700, loss: task a -14.8513, task b -0.0158 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3750, loss: task a -14.8539, task b -0.0170 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3800, loss: task a -14.8567, task b -0.0164 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3850, loss: task a -14.8596, task b -0.0157 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3900, loss: task a -14.8621, task b -0.0164 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 3950, loss: task a -14.8645, task b -0.0159 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 4000, loss: task a -14.8666, task b -0.0167 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 4050, loss: task a -14.8694, task b -0.0141 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 9\n",
      "step 4100, loss: task a -14.8710, task b -0.0168 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4150, loss: task a -14.8731, task b -0.0165 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4200, loss: task a -14.8756, task b -0.0144 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4250, loss: task a -14.8772, task b -0.0175 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4300, loss: task a -14.8792, task b -0.0172 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4350, loss: task a -14.8813, task b -0.0172 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4400, loss: task a -14.8829, task b -0.0176 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4450, loss: task a -14.8846, task b -0.0172 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4500, loss: task a -14.8863, task b -0.0172 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4550, loss: task a -14.8881, task b -0.0168 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4600, loss: task a -14.8895, task b -0.0174 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4650, loss: task a -14.8912, task b -0.0174 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4700, loss: task a -14.8927, task b -0.0175 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4750, loss: task a -14.8942, task b -0.0174 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4800, loss: task a -14.8958, task b -0.0170 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4850, loss: task a -14.8971, task b -0.0175 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4900, loss: task a -14.8988, task b -0.0197 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 4950, loss: task a -14.8998, task b -0.0179 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 9\n",
      "step 5000, loss: task a -14.9012, task b -0.0229 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 8\n",
      "step 5050, loss: task a -14.9014, task b -0.2908 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 22 n_b: 0\n",
      "step 5100, loss: task a -14.9016, task b -0.3336 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5150, loss: task a -14.9017, task b -0.4827 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5200, loss: task a -14.9018, task b -0.5022 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5250, loss: task a -14.9019, task b -1.1277 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5300, loss: task a -14.9019, task b -1.7513 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5350, loss: task a -14.9019, task b -2.1608 | acc: task a 1.0000, task b 0.5000\n",
      "... n_a: 23 n_b: 0\n",
      "step 5400, loss: task a -14.9020, task b -3.3047 | acc: task a 1.0000, task b 0.8500\n",
      "... n_a: 23 n_b: 4\n",
      "step 5450, loss: task a -14.9020, task b -4.1028 | acc: task a 1.0000, task b 0.8500\n",
      "... n_a: 23 n_b: 5\n",
      "step 5500, loss: task a -14.9020, task b -5.2014 | acc: task a 1.0000, task b 0.9500\n",
      "... n_a: 23 n_b: 7\n",
      "step 5550, loss: task a -14.9020, task b -6.4513 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 13\n",
      "step 5600, loss: task a -14.9020, task b -7.6168 | acc: task a 1.0000, task b 0.9500\n",
      "... n_a: 23 n_b: 13\n",
      "step 5650, loss: task a -14.9020, task b -8.8298 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 5700, loss: task a -14.9021, task b -9.0308 | acc: task a 1.0000, task b 0.9500\n",
      "... n_a: 23 n_b: 14\n",
      "step 5750, loss: task a -14.9020, task b -10.7207 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 5800, loss: task a -14.9020, task b -11.4089 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 5850, loss: task a -14.9021, task b -11.9545 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 5900, loss: task a -14.9020, task b -12.3539 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 5950, loss: task a -14.9021, task b -12.7836 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 6000, loss: task a -14.9021, task b -13.0687 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 14\n",
      "step 6050, loss: task a -14.9020, task b -13.2966 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6100, loss: task a -14.9021, task b -13.5050 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6150, loss: task a -14.9021, task b -13.6618 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6200, loss: task a -14.9021, task b -13.7974 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6250, loss: task a -14.9021, task b -13.9063 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6300, loss: task a -14.9021, task b -13.9971 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6350, loss: task a -14.9021, task b -14.0785 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6400, loss: task a -14.9021, task b -14.1513 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6450, loss: task a -14.9021, task b -14.2197 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6500, loss: task a -14.9021, task b -14.2752 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6550, loss: task a -14.9021, task b -14.3235 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6600, loss: task a -14.9021, task b -14.3651 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6650, loss: task a -14.9021, task b -14.4036 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6700, loss: task a -14.9021, task b -14.4377 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6750, loss: task a -14.9021, task b -14.4693 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6800, loss: task a -14.9021, task b -14.4968 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6850, loss: task a -14.9021, task b -14.5208 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6900, loss: task a -14.9021, task b -14.5453 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 6950, loss: task a -14.9021, task b -14.5666 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7000, loss: task a -14.9021, task b -14.5854 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7050, loss: task a -14.9021, task b -14.6031 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7100, loss: task a -14.9021, task b -14.6217 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7150, loss: task a -14.9021, task b -14.6362 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7200, loss: task a -14.9021, task b -14.6504 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7250, loss: task a -14.9021, task b -14.6639 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7300, loss: task a -14.9021, task b -14.6761 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7350, loss: task a -14.9021, task b -14.6874 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7400, loss: task a -14.9021, task b -14.6985 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7450, loss: task a -14.9021, task b -14.7088 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7500, loss: task a -14.9021, task b -14.7181 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7550, loss: task a -14.9021, task b -14.7269 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7600, loss: task a -14.9021, task b -14.7357 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 15\n",
      "step 7650, loss: task a -14.9021, task b -14.7434 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7700, loss: task a -14.9021, task b -14.7513 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7750, loss: task a -14.9021, task b -14.7584 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7800, loss: task a -14.9021, task b -14.7653 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7850, loss: task a -14.9021, task b -14.7718 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7900, loss: task a -14.9021, task b -14.7778 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 7950, loss: task a -14.9021, task b -14.7836 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8000, loss: task a -14.9021, task b -14.7892 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8050, loss: task a -14.9021, task b -14.7945 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8100, loss: task a -14.9021, task b -14.7996 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8150, loss: task a -14.9021, task b -14.8046 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8200, loss: task a -14.9021, task b -14.8089 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8250, loss: task a -14.9021, task b -14.8134 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8300, loss: task a -14.9021, task b -14.8176 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8350, loss: task a -14.9021, task b -14.8216 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8400, loss: task a -14.9021, task b -14.8257 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8450, loss: task a -14.9021, task b -14.8295 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8500, loss: task a -14.9021, task b -14.8327 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8550, loss: task a -14.9021, task b -14.8363 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8600, loss: task a -14.9021, task b -14.8398 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8650, loss: task a -14.9021, task b -14.8430 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8700, loss: task a -14.9021, task b -14.8459 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8750, loss: task a -14.9021, task b -14.8491 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8800, loss: task a -14.9021, task b -14.8518 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8850, loss: task a -14.9021, task b -14.8547 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8900, loss: task a -14.9021, task b -14.8573 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 8950, loss: task a -14.9021, task b -14.8600 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9000, loss: task a -14.9021, task b -14.8624 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9050, loss: task a -14.9021, task b -14.8648 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9100, loss: task a -14.9021, task b -14.8672 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9150, loss: task a -14.9021, task b -14.8694 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9200, loss: task a -14.9021, task b -14.8716 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9250, loss: task a -14.9021, task b -14.8738 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9300, loss: task a -14.9021, task b -14.8758 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9350, loss: task a -14.9021, task b -14.8778 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9400, loss: task a -14.9021, task b -14.8798 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9450, loss: task a -14.9021, task b -14.8816 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9500, loss: task a -14.9021, task b -14.8834 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9550, loss: task a -14.9021, task b -14.8853 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9600, loss: task a -14.9021, task b -14.8869 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9650, loss: task a -14.9021, task b -14.8886 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9700, loss: task a -14.9021, task b -14.8902 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9750, loss: task a -14.9021, task b -14.8918 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9800, loss: task a -14.9021, task b -14.8934 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9850, loss: task a -14.9021, task b -14.8949 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9900, loss: task a -14.9021, task b -14.8964 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "step 9950, loss: task a -14.9021, task b -14.8978 | acc: task a 1.0000, task b 1.0000\n",
      "... n_a: 23 n_b: 16\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# train model\n",
    "train_model(args, model, optimiser, dataset, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 27)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['x_train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0.],\n",
       "       [2., 0.],\n",
       "       [2., 0.],\n",
       "       ...,\n",
       "       [0., 2.],\n",
       "       [0., 2.],\n",
       "       [0., 2.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.centering = False\n",
    "dataset = make_dataset(args)\n",
    "dataset[\"x_train\"][:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "dataset[\"x_train\"][:,-2:] = sc.fit_transform(dataset[\"x_train\"][:,-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.65816255e-01,  2.09611387e-01,  1.21313764e-01,\n",
       "         3.21449473e-02,  3.89962455e-03,  5.35261429e-01,\n",
       "         6.76633846e-01,  3.91605627e-01,  1.03765161e-01,\n",
       "         1.25881422e-02,  7.91065111e-01,  1.00000000e+00,\n",
       "         5.78755599e-01,  1.53354967e-01,  1.86040682e-02,\n",
       "         5.35261429e-01,  6.76633846e-01,  3.91605627e-01,\n",
       "         1.03765161e-01,  1.25881422e-02,  1.65816255e-01,\n",
       "         2.09611387e-01,  1.21313764e-01,  3.21449473e-02,\n",
       "         3.89962455e-03,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 3.46111355e-04,  2.85302627e-03,  1.07672086e-02,\n",
       "         1.86040682e-02,  1.47170293e-02,  2.85302627e-03,\n",
       "         2.35177459e-02,  8.87550456e-02,  1.53354967e-01,\n",
       "         1.21313764e-01,  1.07672086e-02,  8.87550456e-02,\n",
       "         3.34958043e-01,  5.78755599e-01,  4.57833362e-01,\n",
       "         1.86040682e-02,  1.53354967e-01,  5.78755599e-01,\n",
       "         1.00000000e+00,  7.91065111e-01,  1.47170293e-02,\n",
       "         1.21313764e-01,  4.57833362e-01,  7.91065111e-01,\n",
       "         6.25784010e-01,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.41235042e-03,  7.28545780e-03,  1.72059504e-02,\n",
       "         1.86040682e-02,  9.20968160e-03,  1.16421284e-02,\n",
       "         6.00546679e-02,  1.41830159e-01,  1.53354967e-01,\n",
       "         7.59162136e-02,  4.39369336e-02,  2.26643949e-01,\n",
       "         5.35261429e-01,  5.78755599e-01,  2.86504797e-01,\n",
       "         7.59162136e-02,  3.91605627e-01,  9.24848813e-01,\n",
       "         1.00000000e+00,  4.95035897e-01,  6.00546679e-02,\n",
       "         3.09785548e-01,  7.31615629e-01,  7.91065111e-01,\n",
       "         3.91605627e-01,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 5.76327148e-03,  2.97292164e-02,  7.02110200e-02,\n",
       "         7.59162136e-02,  3.75812509e-02,  2.97292164e-02,\n",
       "         1.53354967e-01,  3.62175999e-01,  3.91605627e-01,\n",
       "         1.93858843e-01,  7.02110200e-02,  3.62175999e-01,\n",
       "         8.55345327e-01,  9.24848813e-01,  4.57833362e-01,\n",
       "         7.59162136e-02,  3.91605627e-01,  9.24848813e-01,\n",
       "         1.00000000e+00,  4.95035897e-01,  3.75812509e-02,\n",
       "         1.93858843e-01,  4.57833362e-01,  4.95035897e-01,\n",
       "         2.45060539e-01,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.41235042e-03,  1.16421284e-02,  4.39369336e-02,\n",
       "         7.59162136e-02,  6.00546679e-02,  7.28545780e-03,\n",
       "         6.00546679e-02,  2.26643949e-01,  3.91605627e-01,\n",
       "         3.09785548e-01,  1.72059504e-02,  1.41830159e-01,\n",
       "         5.35261429e-01,  9.24848813e-01,  7.31615629e-01,\n",
       "         1.86040682e-02,  1.53354967e-01,  5.78755599e-01,\n",
       "         1.00000000e+00,  7.91065111e-01,  9.20968160e-03,\n",
       "         7.59162136e-02,  2.86504797e-01,  4.95035897e-01,\n",
       "         3.91605627e-01,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.47170293e-02,  1.86040682e-02,  1.07672086e-02,\n",
       "         2.85302627e-03,  3.46111355e-04,  1.21313764e-01,\n",
       "         1.53354967e-01,  8.87550456e-02,  2.35177459e-02,\n",
       "         2.85302627e-03,  4.57833362e-01,  5.78755599e-01,\n",
       "         3.34958043e-01,  8.87550456e-02,  1.07672086e-02,\n",
       "         7.91065111e-01,  1.00000000e+00,  5.78755599e-01,\n",
       "         1.53354967e-01,  1.86040682e-02,  6.25784010e-01,\n",
       "         7.91065111e-01,  4.57833362e-01,  1.21313764e-01,\n",
       "         1.47170293e-02,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.03765161e-01,  2.09611387e-01,  1.93858843e-01,\n",
       "         8.20849986e-02,  1.59129028e-02,  3.34958043e-01,\n",
       "         6.76633846e-01,  6.25784010e-01,  2.64973621e-01,\n",
       "         5.13674796e-02,  4.95035897e-01,  1.00000000e+00,\n",
       "         9.24848813e-01,  3.91605627e-01,  7.59162136e-02,\n",
       "         3.34958043e-01,  6.76633846e-01,  6.25784010e-01,\n",
       "         2.64973621e-01,  5.13674796e-02,  1.03765161e-01,\n",
       "         2.09611387e-01,  1.93858843e-01,  8.20849986e-02,\n",
       "         1.59129028e-02,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 3.89962455e-03,  3.21449473e-02,  1.21313764e-01,\n",
       "         2.09611387e-01,  1.65816255e-01,  1.25881422e-02,\n",
       "         1.03765161e-01,  3.91605627e-01,  6.76633846e-01,\n",
       "         5.35261429e-01,  1.86040682e-02,  1.53354967e-01,\n",
       "         5.78755599e-01,  1.00000000e+00,  7.91065111e-01,\n",
       "         1.25881422e-02,  1.03765161e-01,  3.91605627e-01,\n",
       "         6.76633846e-01,  5.35261429e-01,  3.89962455e-03,\n",
       "         3.21449473e-02,  1.21313764e-01,  2.09611387e-01,\n",
       "         1.65816255e-01,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 3.75812509e-02,  7.59162136e-02,  7.02110200e-02,\n",
       "         2.97292164e-02,  5.76327148e-03,  1.93858843e-01,\n",
       "         3.91605627e-01,  3.62175999e-01,  1.53354967e-01,\n",
       "         2.97292164e-02,  4.57833362e-01,  9.24848813e-01,\n",
       "         8.55345327e-01,  3.62175999e-01,  7.02110200e-02,\n",
       "         4.95035897e-01,  1.00000000e+00,  9.24848813e-01,\n",
       "         3.91605627e-01,  7.59162136e-02,  2.45060539e-01,\n",
       "         4.95035897e-01,  4.57833362e-01,  1.93858843e-01,\n",
       "         3.75812509e-02,  1.00000000e+00, -1.00000000e+00],\n",
       "       [ 1.59129028e-02,  8.20849986e-02,  1.93858843e-01,\n",
       "         2.09611387e-01,  1.03765161e-01,  5.13674796e-02,\n",
       "         2.64973621e-01,  6.25784010e-01,  6.76633846e-01,\n",
       "         3.34958043e-01,  7.59162136e-02,  3.91605627e-01,\n",
       "         9.24848813e-01,  1.00000000e+00,  4.95035897e-01,\n",
       "         5.13674796e-02,  2.64973621e-01,  6.25784010e-01,\n",
       "         6.76633846e-01,  3.34958043e-01,  1.59129028e-02,\n",
       "         8.20849986e-02,  1.93858843e-01,  2.09611387e-01,\n",
       "         1.03765161e-01,  1.00000000e+00, -1.00000000e+00]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"x_train\"][:10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a3ba60a28f1899318f4810ee01fef19e535f7a46e788980dcac9bebef4b464e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
